{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "from evaluator import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateDistributionMetrics(train_df: pd.DataFrame, val_df: pd.DataFrame, test_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Calculate distribution metrics for user activity, item popularity, and playtime.\n",
    "\n",
    "    :param train_df: DataFrame with training data\n",
    "    :param val_df: DataFrame with validation data\n",
    "    :param test_df: DataFrame with test data\n",
    "\n",
    "    :return: Dictionary with distribution metrics\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # User activity distribution\n",
    "    train_activity = train_df.groupby('user_id')['item_id'].count()\n",
    "    val_activity = val_df.groupby('user_id')['item_id'].count()\n",
    "    test_activity = test_df.groupby('user_id')['item_id'].count()\n",
    "    \n",
    "    # Item popularity distribution\n",
    "    train_pop = train_df['item_id'].value_counts(normalize=True)\n",
    "    val_pop = val_df['item_id'].value_counts(normalize=True)\n",
    "    test_pop = test_df['item_id'].value_counts(normalize=True)\n",
    "    \n",
    "    # Playtime distribution\n",
    "    train_play = train_df['playtime']\n",
    "    val_play = val_df['playtime']\n",
    "    test_play = test_df['playtime']\n",
    "\n",
    "    def jensen_shannon(p, q):\n",
    "        \"\"\"Calculate Jensen-Shannon distance between two distributions.\"\"\"\n",
    "        # Calculate the mean of the two distributions\n",
    "        m = 0.5 * (p + q)\n",
    "        # Calculate Jensen-Shannon divergence\n",
    "        divergence = 0.5 * (stats.entropy(p, m) + stats.entropy(q, m))\n",
    "        # Return the square root of the divergence (to get the distance)\n",
    "        return np.sqrt(divergence)\n",
    "    \n",
    "    # Calculate KL divergence and JS distance for each distribution\n",
    "    for name, train_dist, val_dist, test_dist in [\n",
    "        ('activity', train_activity, val_activity, test_activity),\n",
    "        ('popularity', train_pop, val_pop, test_pop),\n",
    "        ('playtime', train_play, val_play, test_play)\n",
    "    ]:\n",
    "        # Create histogram distributions for comparison\n",
    "        hist_range = (min(train_dist.min(), val_dist.min(), test_dist.min()),\n",
    "                max(train_dist.max(), val_dist.max(), test_dist.max()))\n",
    "        \n",
    "        train_hist, _ = np.histogram(train_dist, bins=50, range=hist_range, density=True)\n",
    "        val_hist, _ = np.histogram(val_dist, bins=50, range=hist_range, density=True)\n",
    "        test_hist, _ = np.histogram(test_dist, bins=50, range=hist_range, density=True)\n",
    "        \n",
    "        # Add small epsilon to avoid division by zero\n",
    "        epsilon = 1e-10\n",
    "        train_hist = train_hist + epsilon\n",
    "        val_hist = val_hist + epsilon\n",
    "        test_hist = test_hist + epsilon\n",
    "        \n",
    "        # Normalize\n",
    "        train_hist = train_hist / train_hist.sum()\n",
    "        val_hist = val_hist / val_hist.sum()\n",
    "        test_hist = test_hist / test_hist.sum()\n",
    "        \n",
    "        # Calculate KL divergence\n",
    "        kl_val_test = stats.entropy(val_hist, test_hist)\n",
    "        kl_train_test = stats.entropy(train_hist, test_hist)\n",
    "    \n",
    "        js_val_test = jensen_shannon(val_hist, test_hist)\n",
    "        js_train_test = jensen_shannon(train_hist, test_hist)\n",
    "        \n",
    "        metrics[f'{name}_kl_val_test'] = kl_val_test\n",
    "        metrics[f'{name}_kl_train_test'] = kl_train_test\n",
    "        metrics[f'{name}_js_val_test'] = js_val_test\n",
    "        metrics[f'{name}_js_train_test'] = js_train_test\n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createValidationPlots(train_df: pd.DataFrame, val_in_df: pd.DataFrame, \n",
    "                             val_out_df: pd.DataFrame, test_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Create visualizations to validate the data splits.\n",
    "\n",
    "    :param train_df: DataFrame with the training interactions.\n",
    "    :param val_in_df: DataFrame with the validation interactions for training history.\n",
    "    :param val_out_df: DataFrame with the validation interactions for future interactions.\n",
    "    :param test_df: DataFrame with the test interactions.\n",
    "    \"\"\"\n",
    "    sns.set(style=\"whitegrid\", font=\"Arial\", context=\"talk\")\n",
    "    colors = sns.color_palette(\"Set2\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "    fig.patch.set_facecolor('white')\n",
    "    \n",
    "    TITLE_SIZE = 18\n",
    "    LABEL_SIZE = 14\n",
    "    TICK_SIZE = 12\n",
    "    LEGEND_SIZE = 12\n",
    "    \n",
    "    def style_axis(ax, title, xlabel, ylabel):\n",
    "        ax.set_title(title, fontsize=TITLE_SIZE, pad=20, fontweight='bold')\n",
    "        ax.set_xlabel(xlabel, fontsize=LABEL_SIZE)\n",
    "        ax.set_ylabel(ylabel, fontsize=LABEL_SIZE)\n",
    "        ax.tick_params(labelsize=TICK_SIZE)\n",
    "        ax.grid(True, linestyle='--', alpha=0.7)\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_linewidth(1.2)\n",
    "    \n",
    "    # User Activity Distribution (top left)\n",
    "    ax1 = axes[0, 0]\n",
    "    train_activity = train_df.groupby('user_id')['item_id'].count()\n",
    "    val_activity = pd.concat([\n",
    "        val_in_df.groupby('user_id')['item_id'].count(),\n",
    "        val_out_df.groupby('user_id')['item_id'].count()\n",
    "    ])\n",
    "    test_activity = test_df.groupby('user_id')['item_id'].count()\n",
    "    \n",
    "    sns.kdeplot(data=train_activity, label='Training Set', ax=ax1, color=colors[0], linewidth=3)\n",
    "    sns.kdeplot(data=val_activity, label='Validation Set', ax=ax1, color=colors[1], linewidth=3)\n",
    "    sns.kdeplot(data=test_activity, label='Test Set', ax=ax1, color=colors[2], linewidth=3)\n",
    "    \n",
    "    style_axis(ax1, \n",
    "               'User Activity Distribution',\n",
    "               'Log Interactions per User',\n",
    "               'Density')\n",
    "    ax1.set_xscale('log')\n",
    "    ax1.legend(fontsize=LEGEND_SIZE, loc='upper right', frameon=False)\n",
    "    \n",
    "    # Item Popularity Distribution (top right)\n",
    "    ax2 = axes[0, 1]\n",
    "    train_pop = train_df['item_id'].value_counts(normalize=True)\n",
    "    val_pop = pd.concat([val_in_df, val_out_df])['item_id'].value_counts(normalize=True)\n",
    "    test_pop = test_df['item_id'].value_counts(normalize=True)\n",
    "    \n",
    "    sns.kdeplot(data=train_pop, label='Training Set', ax=ax2, color=colors[0], linewidth=3)\n",
    "    sns.kdeplot(data=val_pop, label='Validation Set', ax=ax2, color=colors[1], linewidth=3)\n",
    "    sns.kdeplot(data=test_pop, label='Test Set', ax=ax2, color=colors[2], linewidth=3)\n",
    "    \n",
    "    style_axis(ax2,\n",
    "               'Item Popularity Distribution',\n",
    "               'Log Normalized Frequency',\n",
    "               'Density')\n",
    "    ax2.set_xscale('log')\n",
    "    ax2.legend(fontsize=LEGEND_SIZE, loc='upper right', frameon=False)\n",
    "    \n",
    "    # Fold Split Analysis (bottom left)\n",
    "    ax3 = axes[1, 0]\n",
    "    val_in_items = val_in_df.groupby('user_id')['item_id'].count()\n",
    "    val_out_items = val_out_df.groupby('user_id')['item_id'].count()\n",
    "    \n",
    "    split_data = pd.DataFrame({\n",
    "        'Number of Items': pd.concat([val_in_items, val_out_items]),\n",
    "        'Split Type': ['Training History'] * len(val_in_items) + \n",
    "                      ['Future Interactions'] * len(val_out_items)\n",
    "    })\n",
    "    \n",
    "    sns.violinplot(data=split_data, x='Split Type', y='Number of Items', \n",
    "                   ax=ax3, palette=colors[:2], inner='quartile')\n",
    "    \n",
    "    style_axis(ax3,\n",
    "               'Validation Split Analysis',\n",
    "               'Split Type',\n",
    "               'Items per User')\n",
    "    \n",
    "    # Playtime Distribution (bottom right)\n",
    "    ax4 = axes[1, 1]\n",
    "    max_playtime = np.percentile(pd.concat([\n",
    "        train_df['playtime'],\n",
    "        val_in_df['playtime'],\n",
    "        val_out_df['playtime'],\n",
    "        test_df['playtime']\n",
    "    ]), 99)\n",
    "    \n",
    "    sns.kdeplot(data=np.clip(train_df['playtime'], 0, max_playtime), \n",
    "                label='Training Set', ax=ax4, color=colors[0], linewidth=3)\n",
    "    sns.kdeplot(data=np.clip(pd.concat([val_in_df, val_out_df])['playtime'], 0, max_playtime),\n",
    "                label='Validation Set', ax=ax4, color=colors[1], linewidth=3)\n",
    "    sns.kdeplot(data=np.clip(test_df['playtime'], 0, max_playtime),\n",
    "                label='Test Set', ax=ax4, color=colors[2], linewidth=3)\n",
    "    \n",
    "    style_axis(ax4,\n",
    "               'Playtime Distribution',\n",
    "               'Clipped Playtime (99th Percentile)',\n",
    "               'Density')\n",
    "    ax4.legend(fontsize=LEGEND_SIZE, loc='upper right', frameon=False)\n",
    "    \n",
    "    plt.suptitle('Data Validation Visualizations', \n",
    "                 fontsize=22, y=1.05, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print summary statistics\n",
    "    print(\"\\n=== Split Validation Summary ===\")\n",
    "    print(\"\\nUser Activity Statistics:\")\n",
    "    print(f\"Median interactions per user:\")\n",
    "    print(f\"  Training Set: {train_activity.median():.1f}\")\n",
    "    print(f\"  Validation Set: {val_activity.median():.1f}\")\n",
    "    print(f\"  Test Set: {test_activity.median():.1f}\")\n",
    "    \n",
    "    print(\"\\nFold Split Statistics:\")\n",
    "    print(f\"Average items per user:\")\n",
    "    print(f\"  Training History: {val_in_items.mean():.1f}\")\n",
    "    print(f\"  Future Interactions: {val_out_items.mean():.1f}\")\n",
    "    print(f\"Split Ratio (Training:Future): {val_in_items.sum()/val_out_items.sum():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(\n",
    "    '../data/raw/train_interactions.csv', '../data/raw/test_interactions_in.csv')\n",
    "\n",
    "train_data = evaluator.createSampledDataset(evaluator.train_df, 7500, seed=42)\n",
    "\n",
    "# Create splits using your existing methods\n",
    "train_split, val_split = evaluator.createValidationSplit(\n",
    "    train_data, \n",
    "    val_size=0.2, \n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Create fold splits\n",
    "val_in, val_out = evaluator.createFoldInSplit(val_split, seed=42)\n",
    "\n",
    "# Calculate distribution metrics\n",
    "metrics = calculateDistributionMetrics(train_split, val_in, evaluator.test_in_df)\n",
    "print(metrics)\n",
    "\n",
    "createValidationPlots(evaluator.train_df, val_in, val_out, evaluator.test_in_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createItemGraphsFixed(item_data, normalize_weights=False, figsize=(20, 10)) -> plt:\n",
    "    \"\"\"\n",
    "    Creates bipartite network visualizations with fixed positions.\n",
    "\n",
    "    :param item_data: A dictionary where keys are user IDs and values are dictionaries of item IDs and weights.\n",
    "    :param normalize_weights: If True, normalize the weights for each user.\n",
    "    :param figsize: The size of the figure.\n",
    "\n",
    "    :return: The matplotlib plot object.\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add nodes\n",
    "    users = list(item_data.keys())\n",
    "    items = list(set([item for user_items in item_data.values() \n",
    "                     for item in user_items.keys()]))\n",
    "    \n",
    "    G.add_nodes_from(users, bipartite=0)\n",
    "    G.add_nodes_from(items, bipartite=1)\n",
    "    \n",
    "    # Process edges and weights\n",
    "    edges = []\n",
    "    weights = []\n",
    "    edge_labels = {}\n",
    "    \n",
    "    for user in item_data:\n",
    "        user_weights = []\n",
    "        for item, weight in item_data[user].items():\n",
    "            edges.append((user, item))\n",
    "            user_weights.append(weight)\n",
    "        \n",
    "        if normalize_weights:\n",
    "            total_weight = sum(user_weights)\n",
    "            user_weights = [w/total_weight for w in user_weights]\n",
    "            \n",
    "        weights.extend(user_weights)\n",
    "        \n",
    "        for (item, weight), normalized_weight in zip(item_data[user].items(), user_weights):\n",
    "            if normalize_weights:\n",
    "                edge_labels[(user, item)] = f'{normalized_weight:.2f}'\n",
    "            else:\n",
    "                edge_labels[(user, item)] = f'{weight}'\n",
    "    \n",
    "    for edge, weight in zip(edges, weights):\n",
    "        G.add_edge(*edge, weight=weight)\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Create fixed positions\n",
    "    pos = {}\n",
    "    # Position users on the left\n",
    "    for i, user in enumerate(users):\n",
    "        pos[user] = np.array([0, (len(users)-i-1)/(len(users)-1)])\n",
    "    \n",
    "    # Position items on the right in two columns\n",
    "    for i, item in enumerate(items):\n",
    "        if i < len(items)//2:\n",
    "            pos[item] = np.array([1, (len(items)//2-i-1)/(len(items)//2-1)])\n",
    "        else:\n",
    "            pos[item] = np.array([1.2, (len(items)-i-1)/(len(items)-len(items)//2-1)])\n",
    "    \n",
    "    # Draw the graph\n",
    "    nx.draw_networkx_nodes(G, pos, \n",
    "                          nodelist=users, \n",
    "                          node_color='lightblue',\n",
    "                          node_size=500,\n",
    "                          label='Users')\n",
    "    nx.draw_networkx_nodes(G, pos, \n",
    "                          nodelist=items, \n",
    "                          node_color='lightgreen',\n",
    "                          node_size=500,\n",
    "                          label='Items')\n",
    "    \n",
    "    max_weight = max(weights)\n",
    "    edge_widths = [2 * w/max_weight for w in weights]\n",
    "    nx.draw_networkx_edges(G, pos, width=edge_widths, alpha=0.5)\n",
    "    \n",
    "    nx.draw_networkx_labels(G, pos)\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\n",
    "    \n",
    "    title = 'User-Item Network with Weights'\n",
    "    if normalize_weights:\n",
    "        title = 'User-Item Network with Transition Probabilities'\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createItemGraphs(item_data, normalize_weights=False, figsize=(20, 10)) -> plt:\n",
    "    \"\"\"\n",
    "    Creates a bipartite graph of users and items with weights as edge weights.\n",
    "\n",
    "    :param item_data: A dictionary where keys are user IDs and values are dictionaries of item IDs and weights.\n",
    "    :param normalize_weights: If True, normalize the weights for each user.\n",
    "    :param figsize: The size of the figure.\n",
    "\n",
    "    :return: The matplotlib plot object.\n",
    "    \"\"\"\n",
    "    # Create graph\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add nodes\n",
    "    users = list(item_data.keys())\n",
    "    items = list(set([item for user_items in item_data.values() \n",
    "                     for item in user_items.keys()]))\n",
    "    \n",
    "    # Add user nodes\n",
    "    G.add_nodes_from(users, bipartite=0)\n",
    "    # Add item nodes\n",
    "    G.add_nodes_from(items, bipartite=1)\n",
    "    \n",
    "    # Process edges and weights\n",
    "    edges = []\n",
    "    weights = []\n",
    "    edge_labels = {}\n",
    "    \n",
    "    for user in item_data:\n",
    "        user_weights = []\n",
    "        for item, weight in item_data[user].items():\n",
    "            edges.append((user, item))\n",
    "            user_weights.append(weight)\n",
    "            \n",
    "        # Normalize weights if requested\n",
    "        if normalize_weights:\n",
    "            total_weight = sum(user_weights)\n",
    "            user_weights = [w/total_weight for w in user_weights]\n",
    "            \n",
    "        weights.extend(user_weights)\n",
    "        \n",
    "        # Create edge labels\n",
    "        for (item, weight), normalized_weight in zip(item_data[user].items(), user_weights):\n",
    "            if normalize_weights:\n",
    "                edge_labels[(user, item)] = f'{normalized_weight:.2f}'\n",
    "            else:\n",
    "                edge_labels[(user, item)] = f'{weight}'\n",
    "    \n",
    "    # Add edges to graph\n",
    "    for edge, weight in zip(edges, weights):\n",
    "        G.add_edge(*edge, weight=weight)\n",
    "    \n",
    "    # Create the visualization\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Set positions for bipartite graph\n",
    "    pos = nx.spring_layout(G, k=1, iterations=50)\n",
    "    \n",
    "    # Draw the graph\n",
    "    # Draw nodes\n",
    "    nx.draw_networkx_nodes(G, pos, \n",
    "                          nodelist=users, \n",
    "                          node_color='lightblue',\n",
    "                          node_size=500,\n",
    "                          label='Users')\n",
    "    nx.draw_networkx_nodes(G, pos, \n",
    "                          nodelist=items, \n",
    "                          node_color='lightgreen',\n",
    "                          node_size=500,\n",
    "                          label='Items')\n",
    "    \n",
    "    # Draw edges with varying thickness\n",
    "    max_weight = max(weights)\n",
    "    edge_widths = [2 * w/max_weight for w in weights]\n",
    "    nx.draw_networkx_edges(G, pos, width=edge_widths, alpha=0.5)\n",
    "    \n",
    "    # Add labels\n",
    "    nx.draw_networkx_labels(G, pos)\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\n",
    "    \n",
    "    # Add title and legend\n",
    "    title = 'User-Item Network with Weights'\n",
    "    if normalize_weights:\n",
    "        title = 'User-Item Network with Transition Probabilities'\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data = {\n",
    "    'U1': {'CSGO': 150, 'Dota2': 80, 'Minecraft': 30, 'GTA5': 45, \n",
    "           'Witcher3': 60, 'Portal2': 20, 'Cyberpunk': 35},\n",
    "    'U2': {'CSGO': 200, 'EldenRing': 40, 'GTA5': 90, 'RDR2': 70, \n",
    "           'HalfLife2': 25},\n",
    "    'U3': {'Dota2': 120, 'EldenRing': 85, 'Minecraft': 50, 'RDR2': 55,\n",
    "           'Witcher3': 40, 'Portal2': 30, 'Cyberpunk': 65},\n",
    "    'U4': {'CSGO': 90, 'Dota2': 160, 'GTA5': 75, 'Witcher3': 95,\n",
    "           'HalfLife2': 40, 'Cyberpunk': 80},\n",
    "    'U5': {'CSGO': 175, 'Dota2': 70, 'EldenRing': 60, 'Minecraft': 40,\n",
    "           'RDR2': 85, 'Portal2': 35, 'HalfLife2': 30}\n",
    "}\n",
    "\n",
    "# Create visualizations with fixed layout\n",
    "plt1 = createItemGraphsFixed(item_data, normalize_weights=False)\n",
    "plt1.savefig('../output/images/item_network_fixed.png', bbox_inches='tight', dpi=360)\n",
    "\n",
    "plt2 = createItemGraphsFixed(item_data, normalize_weights=True)\n",
    "plt2.savefig('../output/images/transition_network_fixed.png', bbox_inches='tight', dpi=360)\n",
    "\n",
    "# Create visualizations with spring layout\n",
    "plt3 = createItemGraphs(item_data, normalize_weights=False)\n",
    "plt3.savefig('../output/images/item_network_spring.png', bbox_inches='tight', dpi=360)\n",
    "\n",
    "plt4 = createItemGraphs(item_data, normalize_weights=True)\n",
    "plt4.savefig('../output/images/transition_network_spring.png', bbox_inches='tight', dpi=360)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
